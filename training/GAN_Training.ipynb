{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import math\n",
    "import gc\n",
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import transforms\n",
    "from models.models import *\n",
    "from common.datasets import *\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pretrain Generator</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the validation pass\n",
    "def validation(model, validateloader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with tqdm(total=len(validateloader)) as pbar:\n",
    "            for xs, ys in iter(validateloader):\n",
    "                xs, ys = torch.unsqueeze(xs, 1), torch.unsqueeze(ys, 1)\n",
    "                xs, ys = xs.to(device), ys.to(device) # send data to cuda for training\n",
    "                outputs = model(xs) # passes image to the model, and gets a ouput which is the class probability prediction\n",
    "                val_loss += criterion(outputs, ys) # calculates val_loss from model predictions and true labels\n",
    "                pbar.update(1)\n",
    "\n",
    "    return val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test identity\n",
    "path = \"/path/to/data/\" #Change to where your data is stored\n",
    "xpath = path + \"/bone\"\n",
    "ypath = path + \"/flesh\"\n",
    "xnames = os.listdir(xpath)\n",
    "ynames = os.listdir(ypath)\n",
    "split = .2\n",
    "\n",
    "# Get transforms from first scan\n",
    "sample = np.load(xpath + \"/\" + xnames[0])\n",
    "mean = sample.mean()\n",
    "std = sample.std()\n",
    "height = sample.shape[0]\n",
    "sample = None\n",
    "transform = transforms.Compose([transforms.Normalize(mean=[mean], std=[std])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = NumpyDataset(xnames, y=ynames, xpath=xpath, ypath=ypath, transform=transform, zoom=.5, square=True)\n",
    "split_idx = math.floor(len(full) * (1 - split))\n",
    "\n",
    "train, valid = torch.utils.data.random_split(full, (split_idx, len(full) - split_idx))\n",
    "\n",
    "# Get minibatch size\n",
    "bs = 16\n",
    "num_mb = 4\n",
    "mbs = bs // num_mb\n",
    "\n",
    "nw = 4\n",
    "train_loader = DataLoader(train, batch_size=mbs, shuffle=True, num_workers=nw)\n",
    "valid_loader = DataLoader(valid, batch_size=mbs, shuffle=True, num_workers=nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = VNet(height).to(device)\n",
    "# D = ResNet(BasicBlock, [2, 2, 2, 2], sample_size=112, sample_duration=16, num_classes=2).to(device)\n",
    "G_criterion = nn.MSELoss() # mean squared error loss\n",
    "# D_criterion = nn.BCELoss() # binary cross entropy loss\n",
    "G_opt = torch.optim.Adam(G.parameters(), lr=0.0003, betas=(0.5, 0.999))\n",
    "# D_opt = torch.optim.Adam(D.parameters(), lr=0.0003, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./pretrain4\"\n",
    "checkpoint = torch.load(savepath)\n",
    "G.load_state_dict(checkpoint['G_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "valid_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pretrain Generator\n",
    "total_epoch = 40\n",
    "for epoch in range(total_epoch): # loops through number of epochs\n",
    "    running_loss = 0\n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        G_opt.zero_grad()\n",
    "        \n",
    "        for i, data in enumerate(train_loader): # loops through training_loader\n",
    "            G.train()\n",
    "            G.float() # Undo the double() in the validation loop\n",
    "            \n",
    "            # Seperate, fix dimensions, put to device\n",
    "            inputs, labels = data\n",
    "            inputs, labels = torch.unsqueeze(inputs, 1), torch.unsqueeze(labels, 1)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # forward + backward + optimize                                          \n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            outputs = G(inputs) # forward pass and get predictions\n",
    "            \n",
    "            # calculate loss\n",
    "            loss = G_criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # accumulate gradients for the number of minibatches, only update optimiser each batch\n",
    "            if (i + 1) % num_mb == 0:\n",
    "                G_opt.step()\n",
    "                G_opt.zero_grad()\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    val_loss = validation(G, valid_loader, G_criterion)\n",
    "    \n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    valid_losses.append(val_loss/len(valid_loader))\n",
    "  \n",
    "    print(\"Epoch: {}/{}, Training Loss: {}, Validation Loss: {}\".format(epoch+1, total_epoch, running_loss/len(train_loader), val_loss/len(valid_loader)))\n",
    "    print('-' * 20)\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# multiple line plot\n",
    "plt.plot(UNet_t)\n",
    "plt.plot(VNet_t)\n",
    "plt.plot(DVNet_t)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend([\"UNet\", \"VNet\", \"DVNet\"])\n",
    "plt.title(\"Training Losses\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# multiple line plot\n",
    "plt.plot(UNet_v)\n",
    "plt.plot(VNet_v)\n",
    "plt.plot(DVNet_v)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend([\"UNet\", \"VNet\", \"DVNet\"])\n",
    "plt.title(\"Validation Losses\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./pretrain4\"\n",
    "torch.save({'G_state_dict': G.state_dict()}, savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"../testnpys\"\n",
    "transform = transforms.Compose([transforms.Normalize(mean=[mean], std=[std])])\n",
    "get_generations(G, path + \"/generated\", path + \"/bone\", zoom_f=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pretrain Discriminator</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section still does not work on massive, it also may not be necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the validation pass\n",
    "def validation(model, validateloader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        for images, labels in iter(validateloader):\n",
    "            images, labels = images.to(device), labels.to(device) # send data to cuda, where the model is kept\n",
    "            outputs = model(images) # passes image to the model, and gets a ouput which is the class probability prediction\n",
    "            outputs = outputs.double()\n",
    "            labels = labels.double()\n",
    "\n",
    "            val_loss += criterion(outputs, labels) # calculates val_loss from model predictions and true labels\n",
    "            _, idxprediction = torch.max(outputs, 1) # turns class probability predictions to class labels\n",
    "            _, idxlabels = torch.max(labels, 1)\n",
    "\n",
    "            total += labels.size(0) # sums the number of predictions\n",
    "            correct += (idxprediction == idxlabels).sum().item() # sums the number of correct predictions\n",
    "\n",
    "    return val_loss.item(), correct/total # return loss value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test identity\n",
    "path = \"/path/to/data\"\n",
    "xpath = path + \"/bone\"\n",
    "ypath = path + \"/generated\"\n",
    "xnames = os.listdir(xpath)\n",
    "ynames = os.listdir(ypath)\n",
    "split = .2\n",
    "\n",
    "# Get transforms from first scan\n",
    "sample = np.load(xpath + \"/\" + xnames[0])\n",
    "mean = sample.mean()\n",
    "std = sample.std()\n",
    "height = sample.shape[0]\n",
    "sample = None\n",
    "transform = transforms.Compose([transforms.Normalize(mean=[mean], std=[std])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = NumpyClassDataset(xnames, ynames, class1path=xpath, class2path=ypath, transform=transform,square=True)\n",
    "split_idx = math.floor(len(full) * (1 - split))\n",
    "\n",
    "train, valid = torch.utils.data.random_split(full, (split_idx, len(full) - split_idx))\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=15, shuffle=True, num_workers=11)\n",
    "valid_loader = DataLoader(valid, batch_size=15, shuffle=True, num_workers=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = ResNet(BasicBlock, [2, 2, 2, 2], sample_size=112, sample_duration=16, num_classes=2).to(device)\n",
    "criterion = nn.BCELoss() # binary cross entropy loss\n",
    "opt = torch.optim.Adam(D.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./toast\"\n",
    "# train_loader = None\n",
    "# valid_loader = None\n",
    "outputs = None\n",
    "gc.collect()\n",
    "\n",
    "checkpoint = torch.load(savepath)\n",
    "D.load_state_dict(checkpoint['D_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 30\n",
    "for epoch in range(total_epoch): # loops through number of epochs\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_loader): # loops through training_loader\n",
    "        D.train()\n",
    "        D.float()\n",
    "        print(i + 1, \"/\", len(train_loader))\n",
    "        inputs, labels = data \n",
    "        inputs, labels = inputs.to(device), labels.to(device) # send data to cuda for training\n",
    "\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        \n",
    "#         print(\"Input shape:\", inputs.shape)\n",
    "#         print(\"Label shape:\", labels.shape)\n",
    "        \n",
    "        # forward + backward + optimize                                          \n",
    "        opt.zero_grad() # zero the gradients in model parameters\n",
    "        outputs = D(inputs) # forward pass and get predictions\n",
    "        \n",
    "#         print(\"Output shape:\", outputs.shape)\n",
    "        outputs = outputs.float()\n",
    "        labels = labels.float()\n",
    "        \n",
    "        loss = criterion(outputs, labels) # calculate loss\n",
    "        loss.backward() # calculates gradient w.r.t to loss for all parameters in model that have requires_grad=True\n",
    "        opt.step() # iteration all parameters in the model with requires_grad=True and update their weights.\n",
    "\n",
    "        running_loss += loss.item() # sum total loss in current epoch for print later\n",
    "\n",
    "    val_loss, accuracy = validation(D, valid_loader, criterion) # after training for one epoch, run the validation() function to see how the model is doing on the validation dataset\n",
    "    print(\"Epoch: {}/{}, Loss: {}, Val Loss: {}, Val Accuracy: {}\".format(epoch+1, total_epoch, running_loss/len(train_loader), val_loss, accuracy))\n",
    "    print('-' * 20)\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./pretrain_D\"\n",
    "torch.save({'D_state_dict': D.state_dict()}, savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Combine Models (NoGAN)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test identity\n",
    "path = \"/path/to/data/\"\n",
    "xpath = path + \"/bone\"\n",
    "ypath = path + \"/flesh\"\n",
    "xnames = os.listdir(xpath)\n",
    "ynames = os.listdir(ypath)\n",
    "split = .2\n",
    "\n",
    "# Get transforms from first scan\n",
    "sample = np.load(xpath + \"/\" + xnames[0])\n",
    "mean = sample.mean()\n",
    "std = sample.std()\n",
    "height = sample.shape[0]\n",
    "sample = None\n",
    "transform = transforms.Compose([transforms.Normalize(mean=[mean], std=[std])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = NumpyDataset(xnames, y=ynames, xpath=xpath, ypath=ypath, transform=transform, zoom=.5, square=True)\n",
    "train, valid = torch.utils.data.random_split(full, (len(full) - 5, 5))\n",
    "\n",
    "bs = 12\n",
    "nw = 12\n",
    "train_loader = DataLoader(train, batch_size=bs, shuffle=True, num_workers=nw)\n",
    "valid_loader = DataLoader(valid, batch_size=bs, shuffle=True, num_workers=nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = VNet(height).to(device)\n",
    "D = ResNet(BasicBlock, [2, 2, 2, 2], sample_size=112, sample_duration=16, num_classes=2).to(device)\n",
    "G_criterion = nn.MSELoss() # mean squared error loss\n",
    "D_criterion = nn.BCELoss() # binary cross entropy loss\n",
    "G_opt = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_reals = []\n",
    "D_fakes = []\n",
    "G_reals = []\n",
    "\n",
    "for _ in range(bs):\n",
    "    # One sided label smoothing to encourage the discriminator to generalise\n",
    "    D_reals.append([.9, .1])\n",
    "    G_reals.append([1, 0])\n",
    "    D_fakes.append([0, 1])\n",
    "\n",
    "D_reals = torch.FloatTensor(D_reals)\n",
    "D_reals = D_reals.to(device)\n",
    "D_fakes = torch.FloatTensor(D_fakes)\n",
    "D_fakes = D_fakes.to(device)\n",
    "G_reals = torch.FloatTensor(G_reals)\n",
    "G_reals = G_reals.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 5\n",
    "loss_scaling = 30\n",
    "cycles = 1\n",
    "count = 0\n",
    "D_threshold = .2\n",
    "D_loss = D_threshold + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we continue to train the discriminator until some threshold does this mean that we do not need to pretrain the discriminator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savepath = \"./pretrain4\"\n",
    "# checkpoint = torch.load(savepath)\n",
    "# G.load_state_dict(checkpoint['G_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./GAN\"\n",
    "checkpoint = torch.load(savepath)\n",
    "G.load_state_dict(checkpoint['G_state_dict'])\n",
    "D.load_state_dict(checkpoint['D_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    for idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # I still don't know why we need the floats\n",
    "        D.train()\n",
    "        D.float()\n",
    "        G.train()\n",
    "        G.float()\n",
    "        \n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # send data to cuda for training\n",
    "        \n",
    "        print(idx + 1, \"/\", len(train_loader))\n",
    "\n",
    "        # Skip if generator is Cycling or Discriminator is > threshold\n",
    "        \"\"\"\n",
    "          Training Discriminator (D)\n",
    "        \"\"\"\n",
    "        un_inputs = torch.unsqueeze(inputs, 1)\n",
    "\n",
    "        # calculate D's loss for real dataabs\n",
    "        x_outputs = D(un_inputs)\n",
    "        # Fix to handle differences in batch size for last batch\n",
    "        D_x_loss = D_criterion(x_outputs, D_reals[0:len(x_outputs)])\n",
    "\n",
    "        # calculate G's loss for fake data\n",
    "        z_outputs = D(G(inputs))\n",
    "        D_z_loss = D_criterion(z_outputs, D_fakes[0:len(z_outputs)])\n",
    "\n",
    "        # total loss\n",
    "        D_loss = D_x_loss + D_z_loss  \n",
    "        print(\"Discriminator\", D_loss)\n",
    "\n",
    "        # back prop\n",
    "        D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_opt.step()\n",
    "\n",
    "#         if D_loss < D_threshold:\n",
    "#             count = 0    \n",
    "        \n",
    "        if D_loss < D_threshold:\n",
    "            \"\"\"\n",
    "              Training Generator (G)\n",
    "            \"\"\"\n",
    "            \n",
    "            # Generate images\n",
    "            z_outputs = G(inputs)\n",
    "\n",
    "            # Get discrimator loss\n",
    "            D_outputs = D(z_outputs)\n",
    "            D_loss2 = D_criterion(D_outputs, G_reals[0:len(D_outputs)])\n",
    "            G_loss = G_criterion(z_outputs, labels)\n",
    "\n",
    "            # Combine loss\n",
    "            C_loss = G_loss * loss_scaling + D_loss2\n",
    "            print(\"Generator\", G_loss, D_loss2)\n",
    "\n",
    "            # back prop\n",
    "            G.zero_grad()\n",
    "            C_loss.backward()\n",
    "            G_opt.step()\n",
    "            \n",
    "            count += 1\n",
    "    \n",
    "    # Get samples\n",
    "    G.eval()\n",
    "    for (inputs, _) in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = G(inputs)\n",
    "        for j, output in enumerate(outputs):\n",
    "            output.mul_(std).add_(mean)\n",
    "            output = output.detach().cpu().numpy()\n",
    "            np.save(\"../testnpys/GAN/\" + str(epoch) + \"_\" + str(j) + \".npy\", output)\n",
    "    \n",
    "#         if step % 500 == 0:\n",
    "#             print('Epoch: {}/{}, Step: {}, D Loss: {}, G Loss: {}'.format(epoch + 1, max_epoch, step, D_loss.item(), G_loss.item()))\n",
    "        \n",
    "#         if step % 1000 == 0:\n",
    "#             G.eval()\n",
    "\n",
    "#             img = get_sample_image(G, n_noise)\n",
    "#             imsave('samples/{}_step{}.jpg'.format(MODEL_NAME, str(step).zfill(3)), img, cmap='gray')\n",
    "#             G.train()\n",
    "#         step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./GAN\"\n",
    "torch.save({'G_state_dict': G.state_dict(), 'D_state_dict': D.state_dict()}, savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./GAN\"\n",
    "checkpoint = torch.load(savepath)\n",
    "G.load_state_dict(checkpoint['G_state_dict'])\n",
    "D.load_state_dict(checkpoint['D_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Save</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_generations(G, path + \"/GAN\", path + \"/bone\", num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
