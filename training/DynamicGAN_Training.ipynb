{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import math\n",
    "import gc\n",
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import transforms\n",
    "from models.models import *\n",
    "from common.datasets import *\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pretrain Generator</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the validation pass\n",
    "def validation(model, validateloader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with tqdm(total=len(validateloader)) as pbar:\n",
    "            for xs, ys in iter(validateloader):\n",
    "                xs, ys = torch.unsqueeze(xs, 1), torch.unsqueeze(ys, 1)\n",
    "                xs, ys = xs.to(device), ys.to(device) # send data to cuda for training\n",
    "                outputs = model(xs) # passes image to the model, and gets a ouput which is the class probability prediction\n",
    "                val_loss += criterion(outputs, ys) # calculates val_loss from model predictions and true labels\n",
    "                pbar.update(1)\n",
    "\n",
    "    return val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test identity\n",
    "path = \"/path/to/data/\"\n",
    "xpath = path + \"/bone\"\n",
    "ypath = path + \"/flesh\"\n",
    "xnames = os.listdir(xpath)\n",
    "ynames = os.listdir(ypath)\n",
    "split = .2\n",
    "\n",
    "# Get transforms from first scan\n",
    "sample = np.load(xpath + \"/\" + xnames[0])\n",
    "mean = sample.mean()\n",
    "std = sample.std()\n",
    "height = sample.shape[0]\n",
    "sample = None\n",
    "transform = transforms.Compose([transforms.Normalize(mean=[mean], std=[std])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = NumpyDataset(xnames, y=ynames, xpath=xpath, ypath=ypath, transform=transform, zoom=.5, square=True)\n",
    "split_idx = math.floor(len(full) * (1 - split))\n",
    "\n",
    "train, valid = torch.utils.data.random_split(full, (split_idx, len(full) - split_idx))\n",
    "\n",
    "# Get minibatch size\n",
    "bs = 15\n",
    "num_mb = 5\n",
    "mbs = bs // num_mb\n",
    "\n",
    "nw = 4\n",
    "train_loader = DataLoader(train, batch_size=mbs, shuffle=True, num_workers=nw)\n",
    "valid_loader = DataLoader(valid, batch_size=mbs, shuffle=True, num_workers=nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Discriminator and remove output layers\n",
    "D = ResNet(BasicBlock, [2, 2, 2, 2], sample_size=112, sample_duration=16, num_classes=2, conv1_t_size=3)\n",
    "body = nn.Sequential(*list(D.children())[:-3])\n",
    "\n",
    "# Generate VNet\n",
    "G = DynamicVnet(body, img_size=train[0][0].shape, blur=False, blur_final=False,\n",
    "          self_attention=False, norm_type=None, last_cross=True, bottle=False).to(device)\n",
    "G_criterion = nn.MSELoss()\n",
    "G_opt = torch.optim.Adam(G.parameters(), lr=0.0003, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./pretrain_smol\"\n",
    "checkpoint = torch.load(savepath)\n",
    "G.load_state_dict(checkpoint['G_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "valid_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pretrain Generator\n",
    "total_epoch = 40\n",
    "for epoch in range(total_epoch): # loops through number of epochs\n",
    "    running_loss = 0\n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        G_opt.zero_grad()\n",
    "        \n",
    "        for i, data in enumerate(train_loader): # loops through training_loader\n",
    "            G.train()\n",
    "            G.float() # Undo the double() in the validation loop\n",
    "            \n",
    "            # Seperate, fix dimensions, put to device\n",
    "            inputs, labels = data\n",
    "            inputs, labels = torch.unsqueeze(inputs, 1), torch.unsqueeze(labels, 1)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # forward + backward + optimize                                          \n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            outputs = G(inputs) # forward pass and get predictions\n",
    "            \n",
    "            # calculate loss\n",
    "            loss = G_criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # accumulate gradients for the number of minibatches, only update optimiser each batch\n",
    "            if (i + 1) % num_mb == 0:\n",
    "                G_opt.step()\n",
    "                G_opt.zero_grad()\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    val_loss = validation(G, valid_loader, G_criterion)\n",
    "    \n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    valid_losses.append(val_loss/len(valid_loader))\n",
    "  \n",
    "    print(\"Epoch: {}/{}, Training Loss: {}, Validation Loss: {}\".format(epoch+1, total_epoch, running_loss/len(train_loader), val_loss/len(valid_loader)))\n",
    "    print('-' * 20)\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# multiple line plot\n",
    "plt.plot(train_losses)\n",
    "plt.plot(valid_losses)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend([\"train\", \"valid\"])\n",
    "plt.title(\"Dynamic VNet (No Pretrain)\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./pretrain_smol\"\n",
    "torch.save({'G_state_dict': G.state_dict()}, savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_generations(G, \"../generations\", path + \"/bone\", transform=transform, zoom=.5, bs=5, device=device, num=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Combine Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test identity\n",
    "path = \"/path/to/data/\" \n",
    "xpath = path + \"/bone\"\n",
    "ypath = path + \"/flesh\"\n",
    "xnames = os.listdir(xpath)\n",
    "ynames = os.listdir(ypath)\n",
    "split = .2\n",
    "\n",
    "# Get transforms from first scan\n",
    "sample = np.load(xpath + \"/\" + xnames[0])\n",
    "mean = sample.mean()\n",
    "std = sample.std()\n",
    "height = sample.shape[0]\n",
    "sample = None\n",
    "transform = transforms.Compose([transforms.Normalize(mean=[mean], std=[std])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = NumpyDataset(xnames, y=ynames, xpath=xpath, ypath=ypath, transform=transform, zoom=.5, square=True)\n",
    "train, valid = torch.utils.data.random_split(full, (len(full) - 5, 5))\n",
    "\n",
    "# Get minibatch size\n",
    "bs = 16\n",
    "num_mb = 16\n",
    "mbs = bs // num_mb\n",
    "\n",
    "nw = 4\n",
    "train_loader = DataLoader(train, batch_size=mbs, shuffle=True, num_workers=nw)\n",
    "valid_loader = DataLoader(valid, batch_size=mbs, shuffle=True, num_workers=nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Discriminator and remove output layers\n",
    "D = ResNet(BasicBlock, [3, 4, 6, 2], sample_size=112, sample_duration=16, num_classes=2, conv1_t_size=3)\n",
    "body = nn.Sequential(*list(D.children())[:-3])\n",
    "\n",
    "# Generate VNet\n",
    "G = DynamicVnet(body, img_size=train[0][0].shape, blur=False, blur_final=False,\n",
    "          self_attention=False, norm_type=None, last_cross=True,\n",
    "          bottle=False).to(device)\n",
    "D.to(device)\n",
    "\n",
    "D_criterion = nn.BCELoss() # binary cross entropy loss\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=0.0003, betas=(0.9, 0.999))\n",
    "G_criterion = nn.MSELoss()\n",
    "G_opt = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_reals = []\n",
    "D_fakes = []\n",
    "G_reals = []\n",
    "\n",
    "for _ in range(bs):\n",
    "    # One sided label smoothing to encourage the discriminator to generalise\n",
    "    D_reals.append([.9, .1])\n",
    "    G_reals.append([1, 0])\n",
    "    D_fakes.append([0, 1])\n",
    "\n",
    "D_reals = torch.FloatTensor(D_reals)\n",
    "D_reals = D_reals.to(device)\n",
    "D_fakes = torch.FloatTensor(D_fakes)\n",
    "D_fakes = D_fakes.to(device)\n",
    "G_reals = torch.FloatTensor(G_reals)\n",
    "G_reals = G_reals.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./pretrain_smol\"\n",
    "checkpoint = torch.load(savepath)\n",
    "G.load_state_dict(checkpoint['G_state_dict'])\n",
    "# D.load_state_dict(checkpoint['D_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./DGAN\"\n",
    "checkpoint = torch.load(savepath)\n",
    "G.load_state_dict(checkpoint['G_state_dict'])\n",
    "D.load_state_dict(checkpoint['D_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 40\n",
    "loss_scaling = 10\n",
    "D_threshold = .4\n",
    "D_loss = D_threshold\n",
    "generating = False\n",
    "save_folder= \"../generations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    running_G_loss = 0\n",
    "    running_D_loss2 = 0\n",
    "    G_count = 0\n",
    "    \n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        G_opt.zero_grad()\n",
    "        D_opt.zero_grad()\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # I still don't know why we need the floats\n",
    "            D.train()\n",
    "            D.float()\n",
    "            G.train()\n",
    "            G.float()\n",
    "            \n",
    "            # fix dimensions, put to device\n",
    "            inputs, labels = inputs.float(), labels.float()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs, labels = torch.unsqueeze(inputs, 1), torch.unsqueeze(labels, 1)\n",
    "            \n",
    "            # Determine if switch on batch change\n",
    "            if (i + 1) % num_mb == 1:\n",
    "                if D_loss < D_threshold:\n",
    "                    generating = True\n",
    "            \n",
    "            # If statement between modes\n",
    "            if not generating:\n",
    "                # Training Discriminator (D)\n",
    "                \n",
    "                # calculate D's loss for real database\n",
    "                x_outputs = D(inputs)\n",
    "                D_x_loss = D_criterion(x_outputs, D_reals[0:len(x_outputs)])\n",
    "\n",
    "                # calculate G's loss for fake data\n",
    "                z_outputs = D(G(inputs))\n",
    "                D_z_loss = D_criterion(z_outputs, D_fakes[0:len(z_outputs)])\n",
    "\n",
    "                # total loss\n",
    "                D_loss = D_x_loss + D_z_loss\n",
    "\n",
    "                # back prop each minibatch\n",
    "                D_loss.backward()\n",
    "                                \n",
    "                # accumulate gradients for the number of minibatches, only update optimiser each batch\n",
    "                if (i + 1) % num_mb == 0:\n",
    "                    D_opt.step()\n",
    "                    D_opt.zero_grad()\n",
    "                    generating = False\n",
    "                    \n",
    "            else:\n",
    "                #Training Generator (G)\n",
    "            \n",
    "                # Generate images\n",
    "                z_outputs = G(inputs)\n",
    "\n",
    "                # Get discrimator loss\n",
    "                D_outputs = D(z_outputs)\n",
    "                D_loss2 = D_criterion(D_outputs, G_reals[0:len(D_outputs)])\n",
    "                G_loss = G_criterion(z_outputs, labels)\n",
    "\n",
    "                # Combine loss\n",
    "                C_loss = G_loss * loss_scaling + D_loss2\n",
    "                running_G_loss += G_loss.item()\n",
    "                running_D_loss2 += D_loss2.item()\n",
    "                G_count += 1\n",
    "                \n",
    "                # back prop\n",
    "                C_loss.backward()\n",
    "                \n",
    "                if (i + 1) % num_mb == 0:\n",
    "                    # accumulate gradients for the number of minibatches, only update optimiser each batch\n",
    "                    G_opt.step()\n",
    "                    G_opt.zero_grad()\n",
    "                    D_loss += 1\n",
    "                    generating = False\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "    if G_count == 0:\n",
    "        print(\"Epoch: {}/{}, No G training\".format(epoch+1, max_epoch))\n",
    "    else:\n",
    "        print(\"Epoch: {}/{}, Total Loss: {}, Pixel Loss: {}, Adversarial Loss: {}\".format(epoch+1, max_epoch, (running_D_loss2 + loss_scaling * running_G_loss)/G_count, running_G_loss/G_count, running_D_loss2/G_count))\n",
    "    \n",
    "    # Get samples\n",
    "    gc.collect()\n",
    "    with torch.no_grad():\n",
    "        G.eval()\n",
    "        i = 0\n",
    "\n",
    "        for (inputs, _) in valid_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            inputs = torch.unsqueeze(inputs, 1)\n",
    "            outputs = G(inputs)\n",
    "            for output in outputs:\n",
    "                output.mul_(std).add_(mean)\n",
    "                output = output.detach().cpu().numpy()\n",
    "                np.save(save_folder + \"/\" + str(epoch) + \"_\" + str(i) + \".npy\", output[0])\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./pretrain_big\"\n",
    "torch.save({'G_state_dict': G.state_dict(), 'D_state_dict': D.state_dict()}, savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./DGAN\"\n",
    "checkpoint = torch.load(savepath)\n",
    "G.load_state_dict(checkpoint['G_state_dict'])\n",
    "D.load_state_dict(checkpoint['D_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_generations(G, \"../generations\", path + \"/bone\", transform=transform, zoom=.5, bs=5, device=device, num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
